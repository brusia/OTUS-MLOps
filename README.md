# OTUS-MLOps

Данный репозиторий создан для выполнения домашних заданий по курсу MLOps платформы обучения OTUS.

<!-- Start of Hometask 2 block -->

## Задание 2

В рамках задания 2 курса разработан terraform-скрипт для создания Yandex Storage, Data Proc кластера и соответствующей инфраструктуры.

Инфраструктура terraform разделена на 2 модуля (storage и dataproc) для более гибкого управления. Управление инфраструктурой осуществляется с помощью make-команд.

### Использование

#### Для создания Data Proc кластера используется скрипт create_hadoop

#### Для удаления Data Proc кластера -- скрипт destroy

При вызове destroy созданное ранее (или вместе с Data Proc кластером) облачное хранилище со всем его содержимым НЕ удаляется.

При разворачивании инфраструктуры скрипт копирует данные из заданного бакета (otus-mlops-source-data) в целевой только в случае, если целевой бакет был пуст. Таким образом при повторном разворачивании dataproc повторное копирование производиться не будет.

В реализованном варианте также нет необходимости заходить на master-ноду мануально, так как запуск скриптов копирования из целевого бакета в распределённую hadoop систему происходит автоматически во время создания proxy-виртуальной машины. Соответствующий лог прилагаю.

[Log Snapshot](docs/hometasks/02/listing-hdfs.png)

Логи исполнения на управляющей ноде dataproc кластера также доступны по префиксу logs/ в целевом бакете.

#### Для создания Data Proc кластера (с копированием данных), выполнения полезной работы (пока никакой :) и последующего удаления созданного кластера -- скрипт compute

#### Целевой бакет

s3://brusia-bucket/

Префикс данных: data/raw/

#### Рассчёты биллинга

[Billing Analyse](docs/hometasks/02/billing-analyse.md)

### Прочие комментарии

- В ходе выполнения задания поторопилась закоммитить промежуточные результаты: .gitignore почему-то не подхватился корректно и файлик terraform.tfvars утёк в git (но только он). В результате пришлось отозвать скомпрометированный OAuth-token и выпустить новый.

- Кроме того, не вполне понравилось реализованное разбиение terraform-инфраструктуры на модули (в части переменных variables не обошлось без копирования из основного модуля в подмодули, что потенциально может приводить к ошибкам при добавлении изменений). Пока нет понимания, как это можно унифицировать.

- В разработанной инфраструктуре используется 2 сервисных аккаунта: один работает исключительно с облачным хранилищем, второй с dataproc кластером и виртуальной машиной. Каждый из сервисных аккаунтов объявлен в соответствующем модуле.

<!-- End of Hometask 2 block. -->

## Oбщие положения

Для экономии места выполненные (и принятые) задания перемещены из главного файла README.md текущего репозитория и скрыты в соответствующих каталогах (docs/hometasks/<task_number>)

Актуальное задание (для проверки) будет размещено в текущей версии README.md
Список предыдущих заданий

[Hometask 1](docs/hometasks/hometask1.md)

## TODO

- Добавить линтинг и pre-commit проверки локально и на CI
