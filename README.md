# OTUS-MLOps

Данный репозиторий создан для выполнения домашних заданий по курсу MLOps платформы обучения OTUS.

<!-- Start of Hometask 3 block -->

## Задание 3

В рамках задания реализован скрипт для анализа данных (также разработана программная инфраструктура, поддерживающая возможное расширение для анализа произвольного набора данных, предусмотрено гибкое добавление анализаторов, есть возможность расширения для произвольного датасета) и очистки данных.

В силу того, что предоставленный набор для анализа чрезвычайно велик для единовременной загрузки в оперативную память, обработка ведётся батчами. Так как анализируемые данные располагаются во времени, каждый батч содержит срез датасета за определённые сутки. Обработка ведётся итеративно: в качестве reference данных для текущего дня используются данные за предыдущий день (если таковые имеются). Итоговые результаты выгружаются на s3 (откуда мы можем предоставить их Data Engeneer-ам для проведения дальнейших исследований и получения рекомендаций по доработке реализованного инструмента).

В рамках вполнение данной работы в качестве упражнения реализованы разные способны анализа данных, как с использованием утилит apache pyspark, так и классические анализаторы, работающие с pandas. Для рассчёта базовых статистик -- cм. анализатор SparkBaseStatisticsDataAnalyser -- среднего значения, среднеквадратичного отклонения, минимального и максимального значений, медианы, 25 и 75 процентилей, коэффициента ассимметрии и риска "толстых хвостов" -- используются данный в формате pyspark. Остальные анализаторы (на основе evidently, ruptures и scipy.stats) рассчитываются на основе тех же данных (или их подмножества) в формате pandas.

Результаты анализа доступны в соответствующем бакете:
s3://brusia-bucket/data-analyse/

Для очистки данных реализованно кастомизированное (зависящее от конкретного вида данных) решение, в ходе которого для текущего набора данных выполняется очитка пропущенных значения (отрицательные, нулевые или пропущенные значения для переменных amount, terminal_id, customer_id, transaction_id). Затем этот набор очищается от выбросов и нормируется при помощи средств pyspark.ml.feature, обученных на reference данных (модель получается на предыдущем шаге итерационного процесса). На текущем наборе обучается новая модель препроцессинга данных --  в данном случае используется MinMaxScaler (возможно расширение функциональности на произвольный выбор Scaler-а). Модели препроцессинга для следующего шага, а также очищенные и нормализованные данные помещаются в соответствующие места на s3.

Очищенные данные в формате parquet доступны по ссылке:
s3://brusia-bucket/data/processed/

Модели для препроцессинга данных:
s3://brusia-bucket/models/data_preprocess/

### Прочие комментарии

- По инфраструктуре: В ходе работы столкнулась с ограничением по доступным версиям python для предоставляемого облаком yandex cloud сервиса data processing (общалась с поддержкой, в ходе чего выяснилось, что версия data processing 2.2 распространяется с предустановленным python3.11, однако в этой версии кластер не установлен hdfs).

Использование старой версии интерпретатора существенно ограничивает возможности разработки: нет нормальной поддержки линтинга, статической проверки кода, pre-commitа и аннотации большинства современных библиотек (в том числе pandas, повсемество используемой для задач машинного обучения). Тем не менее для выполнения базовых задач курса предоставленная версия подходит.

Для расширения возможностей разработки имеет смысл самостоятельно развернуть hadoop-кластер (например, с использованием docker-compose). Поэкспериментирую, если останется свободное время между выполнением домашних заданий курса (или уже после его окончания).

- В текущей реализации дата-специфичные зависимости вынесены в константы. Для более гибкого использования возможно разширение текущей функциональности с последующим вынесением касмомизированных значений в виде параметров. Таким образом может быть достигнута более общая реализация универсального подхода к обработке и подготовке данных, а также гарантируется быстрое и удобное переиспользование для целого ряда подобных (однотипных) задач.

- Поддержка evidently, ruptures и других анализаторов может быть не вполне релевантна для решения поставленной курсом задачи (антифрод системы), однако наглядно демонтрирует возможность гибкого расширения функциональности фреймворка на другие задачи.

- В ходе дальнейшей работы в рамка выполнения домашнего задания 5 планируется декомпозировать исполнение одной итерации на один запуск apache aiflow pipeline-а, эмулируя таким образом обработку поступления новых данных в режиме "реального времени".

<!-- End of Hometask 3 block. -->

## Oбщие положения

Для экономии места выполненные (и принятые) задания перемещены из главного файла README.md текущего репозитория и скрыты в соответствующих каталогах (docs/hometasks/<task_number>/hometask<task_number>.md)

Актуальное задание (для проверки) будет размещено в текущей версии README.md
Список предыдущих заданий

[Hometask 1](docs/hometasks//01/hometask1.md)
[Hometask 2](docs/hometasks/02/hometask2.md)
[Hometask 3](docs/hometasks/03/hometask3.md)
