# Задание 2

В рамках задания 2 курса разработан terraform-скрипт для создания Yandex Storage, Data Proc кластера и соответствующей инфраструктуры.

Инфраструктура terraform разделена на 2 модуля (storage и dataproc) для более гибкого управления. Управление инфраструктурой осуществляется с помощью make-команд.

## Использование

### Для создания Data Proc кластера используется скрипт create_hadoop

### Для удаления Data Proc кластера -- скрипт destroy

При вызове destroy созданное ранее (или вместе с Data Proc кластером) облачное хранилище со всем его содержимым НЕ удаляется.

При разворачивании инфраструктуры скрипт копирует данные из заданного бакета (otus-mlops-source-data) в целевой только в случае, если целевой бакет был пуст. Таким образом при повторном разворачивании dataproc повторное копирование производиться не будет.

В реализованном варианте также нет необходимости заходить на master-ноду мануально, так как запуск скриптов копирования из целевого бакета в распределённую hadoop систему происходит автоматически во время создания proxy-виртуальной машины. Соответствующий лог прилагаю.

[Log Snapshot](listing-hdfs.png)

Логи исполнения на управляющей ноде dataproc кластера также доступны по префиксу logs/ в целевом бакете.

### Для создания Data Proc кластера (с копированием данных), выполнения полезной работы (пока никакой :) и последующего удаления созданного кластера -- скрипт compute

### Целевой бакет

s3://brusia-bucket/

Префикс данных: data/raw/

### Рассчёты биллинга

[Billing Analyse](billing-analyse.md)

### Прочие комментарии

- В ходе выполнения задания поторопилась закоммитить промежуточные результаты: .gitignore почему-то не подхватился корректно и файлик terraform.tfvars утёк в git (но только он). В результате пришлось отозвать скомпрометированный OAuth-token и выпустить новый.

- Кроме того, не вполне понравилось реализованное разбиение terraform-инфраструктуры на модули (в части переменных variables не обошлось без копирования из основного модуля в подмодули, что потенциально может приводить к ошибкам при добавлении изменений). Пока нет понимания, как это можно унифицировать.

- В разработанной инфраструктуре используется 2 сервисных аккаунта: один работает исключительно с облачным хранилищем, второй с dataproc кластером и виртуальной машиной. Каждый из сервисных аккаунтов объявлен в соответствующем модуле.
